{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extractor import FeatureExtractor\n",
    "import sys\n",
    "import numpy as np\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score,accuracy_score, make_scorer\n",
    "from sklearn.base import clone\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow.keras.utils as np_utils\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the HDF5 file\n",
    "\n",
    "# Define here the correct DATA_FOLDER path !!\n",
    "DATA_FOLDER = Path(\"w:/\")\n",
    "filepath = DATA_FOLDER / \"prediction.seg\"\n",
    "\n",
    "file = h5py.File(filepath, 'r')\n",
    "\n",
    "# Access the dataset\n",
    "amplitude_dataset = file['amplitude/images']\n",
    "phase_dataset = file['phase/images']\n",
    "label_dataset = file['label/ground_truth']\n",
    "mask_dataset = file['mask/images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in train and test data and make sure that all classes all represented with the correct ratios\n",
    "\n",
    "split = 0.8  # 80% used for training\n",
    "\n",
    "# Get unique labels and their corresponding indices\n",
    "unique_labels, label_indices = np.unique(label_dataset, return_inverse=True)\n",
    "\n",
    "# Initialize train and test datasets\n",
    "phase_dataset_train = []\n",
    "phase_dataset_test = []\n",
    "amplitude_dataset_train = []\n",
    "amplitude_dataset_test = []\n",
    "mask_dataset_train = []\n",
    "mask_dataset_test = []\n",
    "label_train = []\n",
    "label_test = []\n",
    "\n",
    "# Iterate over each unique label\n",
    "for label in range(len(unique_labels)):\n",
    "    \n",
    "    # Get indices corresponding to the current label\n",
    "    label_indices_current = np.where(label_indices == label)[0]\n",
    "\n",
    "    # Calculate the split index for the current label\n",
    "    k = int(np.ceil(split * len(label_indices_current)))\n",
    "\n",
    "    # Create a random permutation of indices for the current label\n",
    "    indices_current = np.random.permutation(len(label_indices_current))\n",
    "\n",
    "    # Sort the indices to avoid errors\n",
    "    indices_train = np.sort(indices_current[:k])\n",
    "    indices_test = np.sort(indices_current[k:])\n",
    "\n",
    "\n",
    "    # Assign shuffled data to train and test sets for the current label\n",
    "    phase_dataset_train.extend(phase_dataset[label_indices_current[indices_train]])\n",
    "    phase_dataset_test.extend(phase_dataset[label_indices_current[indices_test]])\n",
    "    amplitude_dataset_train.extend(amplitude_dataset[label_indices_current[indices_train]])\n",
    "    amplitude_dataset_test.extend(amplitude_dataset[label_indices_current[indices_test]])\n",
    "    mask_dataset_train.extend(mask_dataset[label_indices_current[indices_train]])\n",
    "    mask_dataset_test.extend(mask_dataset[label_indices_current[indices_test]])\n",
    "    label_train.extend(label_dataset[label_indices_current[indices_train]])\n",
    "    label_test.extend(label_dataset[label_indices_current[indices_test]])\n",
    "\n",
    "# Convert the train and test datasets to arrays\n",
    "phase_dataset_train = np.array(phase_dataset_train)\n",
    "phase_dataset_test = np.array(phase_dataset_test)\n",
    "amplitude_dataset_train = np.array(amplitude_dataset_train)\n",
    "amplitude_dataset_test = np.array(amplitude_dataset_test)\n",
    "mask_dataset_train = np.array(mask_dataset_train)\n",
    "mask_dataset_test = np.array(mask_dataset_test)\n",
    "label_train = np.array(label_train)\n",
    "label_test = np.array(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Data Augmentation on the training data. For that we create an instance of the ImageDataGenerator class with specified transformations\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=0.1,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Reshape to have a 4D shape (samples, height, width, channels)\n",
    "phase_data = np.reshape(phase_dataset_train, (phase_dataset_train.shape[0], phase_dataset_train.shape[1], phase_dataset_train.shape[2], 1))\n",
    "amplitude_data = np.reshape(amplitude_dataset_train, (amplitude_dataset_train.shape[0], amplitude_dataset_train.shape[1], amplitude_dataset_train.shape[2], 1))\n",
    "mask_data = np.reshape(mask_dataset_train, (mask_dataset_train.shape[0], mask_dataset_train.shape[1], mask_dataset_train.shape[2], 1))\n",
    "\n",
    "# Help lists\n",
    "phase_train_pre = []\n",
    "amplitude_train_pre = []\n",
    "mask_train_pre = []\n",
    "\n",
    "seed = 42\n",
    "\n",
    "for i in range(phase_data.shape[0]):\n",
    "\n",
    "    seed += 1  # Use a different seed for each pair of images\n",
    "    batch1_seed = datagen.flow(np.array([phase_data[i]]), batch_size=1, seed=seed).next()[0]\n",
    "    batch2_seed = datagen.flow(np.array([amplitude_data[i]]), batch_size=1, seed=seed).next()[0]\n",
    "    batch3_seed = datagen.flow(np.array([mask_data[i]]), batch_size=1, seed=seed).next()[0]\n",
    "    \n",
    "    phase_train_pre.append(batch1_seed[:])\n",
    "    amplitude_train_pre.append(batch2_seed[:])\n",
    "    mask_train_pre.append(batch3_seed[:])\n",
    "\n",
    "\n",
    "    if len(phase_train_pre) >= phase_data.shape[0]:\n",
    "        break\n",
    "\n",
    "# Convert to arrays\n",
    "phase_train_pre = np.array(phase_train_pre)\n",
    "amplitude_train_pre = np.array(amplitude_train_pre)\n",
    "mask_train_pre = np.array(mask_train_pre)\n",
    "\n",
    "\n",
    "# Reshape augmented_images back to a 3D shape (samples, height, width)\n",
    "phase_train_pre = np.reshape(phase_train_pre,(phase_train_pre.shape[0], phase_train_pre.shape[1], phase_train_pre.shape[2]))\n",
    "amplitude_train_pre = np.reshape(amplitude_train_pre, (amplitude_train_pre.shape[0], amplitude_train_pre.shape[1], amplitude_train_pre.shape[2]))\n",
    "mask_train_pre = np.reshape(mask_train_pre, (mask_train_pre.shape[0], mask_train_pre.shape[1], mask_train_pre.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to remove NaN values from the images. We replace those values with the minimum non-NaN found in each image\n",
    "\n",
    "# Replace NaN values in phase train images with the minimum value of each image\n",
    "phase_train = phase_train_pre\n",
    "for i, img in enumerate(phase_train):\n",
    "    if np.isnan(np.min(img)):\n",
    "        min = np.nanmin(img)\n",
    "        img[np.isnan(img)] = min\n",
    "\n",
    "# Replace NaN values in phase test images with the minimum value of each image\n",
    "phase_test = phase_dataset_test\n",
    "for i, img in enumerate(phase_test):\n",
    "    if np.isnan(np.min(img)):\n",
    "        min = np.nanmin(img)\n",
    "        img[np.isnan(img)] = min\n",
    "\n",
    "# Replace NaN values in amplitude train images with the minimum value of each image\n",
    "amplitude_train = amplitude_train_pre\n",
    "for i, img in enumerate(amplitude_train):\n",
    "    if np.isnan(np.min(img)):\n",
    "        min = np.nanmin(img)\n",
    "        img[np.isnan(img)] = min\n",
    "\n",
    "# Replace NaN values in amplitude test images with the minimum value of each image\n",
    "amplitude_test = amplitude_dataset_test\n",
    "for i, img in enumerate(amplitude_test):\n",
    "    if np.isnan(np.min(img)):\n",
    "        min = np.nanmin(img)\n",
    "        img[np.isnan(img)] = min\n",
    "\n",
    "# Replace NaN values in amplitude train images with the minimum value of each image\n",
    "mask_train = mask_train_pre\n",
    "for i, img in enumerate(mask_train):\n",
    "    if np.isnan(np.min(img)):\n",
    "        min = np.nanmin(img)\n",
    "        img[np.isnan(img)] = min\n",
    "    img = np.round(img)\n",
    "\n",
    "# Convert to avoid errors\n",
    "mask_train = mask_train.astype(int)\n",
    "mask_train = np.array(mask_train, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframes with the features\n",
    "fe_train = FeatureExtractor(phase_train, amplitude_train, mask_train)\n",
    "fe_test = FeatureExtractor(phase_test, amplitude_test, mask_dataset_test)\n",
    "\n",
    "fe_train.extract_features()\n",
    "fe_test.extract_features()\n",
    "\n",
    "df_train = fe_train.features\n",
    "df_test = fe_test.features\n",
    "\n",
    "# Define Train and test Dataframes\n",
    "X_train = df_train.copy()\n",
    "X_test = df_test.copy()\n",
    "y_train = label_train\n",
    "y_test = label_test\n",
    "\n",
    "# Add the labels\n",
    "df_train['Labels'] = label_train\n",
    "df_test['Labels'] = label_test\n",
    "\n",
    "df = pd.concat([df_train, df_test])\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df_train in a csv file\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "folder_name = 'Data'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# Save the DataFrame to a CSV file inside the folder\n",
    "file_path = os.path.join(folder_name, 'training_data.csv')\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows with NaN values. If everything done correctly the output should be 0\n",
    "rows_with_nan = df_train.isna().any(axis=1).sum()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of rows with NaN values:\", rows_with_nan)\n",
    "\n",
    "# Iterate over rows and print column names with NaN values\n",
    "for index, row in df.iterrows():\n",
    "    nan_columns = row.index[row.isna()].tolist()\n",
    "    if len(nan_columns) > 0:\n",
    "        print(f\"NaN values in row {index+1} appear in columns: {nan_columns}, label: {df['Labels'][index+1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Column Transformer\n",
    "def col_transf(df):\n",
    "    num_sc = MinMaxScaler()\n",
    "\n",
    "    pipe= Pipeline(steps=[(\"MinMaxScaler\", num_sc)])\n",
    "\n",
    "    pred_column = \"Labels\"\n",
    "\n",
    "    # Get a list of all columns except the prediction column\n",
    "    num_feat = df.columns[df.columns != pred_column]\n",
    "\n",
    "    ct = ColumnTransformer(transformers=[(\"NumericalTransformer\", pipe, num_feat)])\n",
    "\n",
    "    return ct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SVC Pipeline and return best estimator based on the grid search\n",
    "def bestSVC(ct, X_train, y_train):\n",
    "\n",
    "    pip = Pipeline([\n",
    "    ('ColumnTransformer', ct),\n",
    "    ('classifier', SVC(max_iter=1000000, probability=True))\n",
    "    ])\n",
    "\n",
    "    gs_param = {\n",
    "    'classifier__kernel' : ['linear', 'rbf', 'sigmoid'],\n",
    "    'classifier__C' : [0.3, 0.4, 0.5, 0.7, 1.0],\n",
    "    'classifier__gamma' : [0.004, 0.005, 0.006, 0.01, 0.05, 0.1 ,0.5]\n",
    "    } \n",
    "    \n",
    "    stratified = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
    "\n",
    "    gs = GridSearchCV(pip, gs_param, refit=True, cv=stratified)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Random Forest Pipeline and return best estimator based on the grid search\n",
    "def bestRFC(ct, X_train, y_train):\n",
    "\n",
    "    pipe_rfc = Pipeline([\n",
    "    ('ColumnTransformer', ct),\n",
    "    ('classifier', RFC(random_state=12))\n",
    "    ])\n",
    "\n",
    "    gs_param_rfc = {\n",
    "        'classifier__n_estimators' : [10, 20, 50],\n",
    "        'classifier__max_features' : [2, 4, 8, 12],\n",
    "        'classifier__max_depth' : [4, 10, 16, 20]\n",
    "    }\n",
    "    \n",
    "    stratified_rfc = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "    gs_rfc = GridSearchCV(pipe_rfc, gs_param_rfc, refit=True, cv=stratified_rfc)\n",
    "\n",
    "    gs_rfc.fit(X_train, y_train)\n",
    "\n",
    "    return gs_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build kNN Pipeline and return best estimator based on the grid search\n",
    "def bestKNN(ct, X_train, y_train):\n",
    "\n",
    "    pipe_knn = Pipeline([\n",
    "    ('ColumnTransformer', ct),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    gs_param_knn = {\n",
    "        'classifier__n_neighbors' : [2, 3, 5, 7],\n",
    "        'classifier__weights' : ['uniform', 'distance'],\n",
    "        'classifier__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "    \n",
    "    stratified_knn = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "    gs_knn = GridSearchCV(pipe_knn, gs_param_knn, refit=True, cv=stratified_knn)\n",
    "\n",
    "    gs_knn.fit(X_train, y_train)\n",
    "\n",
    "    return gs_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestNaiveBayes(ct, X_train, y_train):\n",
    "    \n",
    "    pip = Pipeline([\n",
    "        ('ColumnTransformer', ct),\n",
    "        ('classifier', GaussianNB())\n",
    "    ])\n",
    "\n",
    "    gs_param = {}\n",
    "\n",
    "    stratified = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
    "\n",
    "    gs = GridSearchCV(pip, gs_param, refit=True, cv=stratified)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return accuracy\n",
    "def calculate_accuracy(X_train, y_train, X_test, y_test, model):\n",
    "    acc_train = model.score(X_train, y_train)\n",
    "    acc_test = model.score(X_test, y_test)\n",
    "    return acc_train, acc_test\n",
    "\n",
    "# Return balanced accuracy \n",
    "def calculate_bal_accuracy(X_train, y_train, X_test, y_test, model):\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    bacc_train = balanced_accuracy_score(y_train, y_pred_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    bacc_test = balanced_accuracy_score(y_test, y_pred_test)\n",
    "    return bacc_train, bacc_test\n",
    "\n",
    "# Return accuracy with class_weights = true\n",
    "def calculate_accuracy_w(X_train, y_train, X_test, y_test, model):\n",
    "    model_w = clone(model)\n",
    "    model_w[\"classifier\"].set_params(class_weight='balanced')\n",
    "    model_w.fit(X_train, y_train)\n",
    "    acc_train_w = model_w.score(X_train,y_train)\n",
    "    acc_test_w = model_w.score(X_test,y_test)\n",
    "    return acc_train_w, acc_test_w \n",
    "\n",
    "# Return balanced accuracy with class_weights = true\n",
    "def calculate_bal_accuracy_w(X_train, y_train, X_test, y_test, model):\n",
    "    model_w = clone(model)\n",
    "    model_w[\"classifier\"].set_params(class_weight='balanced')\n",
    "    model_w.fit(X_train, y_train)\n",
    "    y_pred_train = model_w.predict(X_train)\n",
    "    bacc_train_w = balanced_accuracy_score(y_train, y_pred_train)\n",
    "    y_pred_test = model_w.predict(X_test)\n",
    "    bacc_test_w = balanced_accuracy_score(y_test, y_pred_test)\n",
    "    return bacc_train_w, bacc_test_w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the classes in the correct order (important for the confusion matrix)\n",
    "def unique_labels(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "\n",
    "    # Get unique labels from true and predicted labels\n",
    "    unique_labels = sorted(set(y_true) | set(y_pred))\n",
    "\n",
    "    # Print the unique labels in the order they appear\n",
    "    return unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices for train and test sets\n",
    "def plot_confusion(model, X_train, y_train, X_test, y_test):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    labels = unique_labels(model, X_test, y_test)\n",
    "    labels = [label.decode() for label in labels]\n",
    "\n",
    "    # Best estimator classifier on training data\n",
    "    cm_best_train = confusion_matrix(y_train, model.predict(X_train))\n",
    "    sns.heatmap(cm_best_train, annot=True,fmt='d', ax=axs[0], cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    axs[0].set_xlabel('Predicted labels');axs[0].set_ylabel('True labels'); \n",
    "    axs[0].set_title('Best estimator classifier on training data')\n",
    "\n",
    "    # Best estimator classifier on test data\n",
    "    cm_best_test = confusion_matrix(y_test, model.predict(X_test))\n",
    "    sns.heatmap(cm_best_test, annot=True,fmt='d', ax=axs[1], cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    axs[1].set_xlabel('Predicted labels');axs[1].set_ylabel('True labels'); \n",
    "    axs[1].set_title('Best estimator classifier on test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, folder_path, file_name):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    joblib.dump(model, file_path)\n",
    "    print(f\"Model saved at {file_path}\")\n",
    "\n",
    "\n",
    "def load_model(folder_path, file_name):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        return joblib.load(file_path)\n",
    "    else:\n",
    "        print(f\"Model file '{file_path}' does not exist.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = col_transf(X_train)\n",
    "svc_model = bestSVC(ct, X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "save_model(svc_model, \"models\", \"best_svc_model.pkl\")\n",
    "\n",
    "# Load the model\n",
    "loaded_svc_model = load_model(\"models\", \"best_svc_model.pkl\")\n",
    "\n",
    "acc_train, acc_test = calculate_accuracy(X_train, y_train, X_test, y_test, loaded_svc_model)\n",
    "bacc_train, bacc_test = calculate_bal_accuracy(X_train, y_train, X_test, y_test, loaded_svc_model)\n",
    "acc_train_w, acc_test_w = calculate_accuracy_w(X_train, y_train, X_test, y_test, loaded_svc_model)\n",
    "bacc_train_w, bacc_test_w = calculate_bal_accuracy_w(X_train, y_train, X_test, y_test, loaded_svc_model)\n",
    "\n",
    "print(f\"\\nAccuracy on the train set: {acc_train}\")\n",
    "print(f\"Accuracy on the test set: {acc_test}\")\n",
    "\n",
    "print(f\"\\nBalanced Accuracy on the train set best SVC: {bacc_train}\")\n",
    "print(f\"Balanced Accuracy on the test set best SVC: {bacc_test}\")\n",
    "\n",
    "print(f\"\\nAccuracy on the train set (class weights): {acc_train_w}\")\n",
    "print(f\"Accuracy on the test (class weights): {acc_test_w}\")\n",
    "\n",
    "print(f\"\\nBalanced Accuracy on the train set (class weights): {bacc_train_w}\")\n",
    "print(f\"Balanced Accuracy on the test set (class weights): {bacc_test_w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(svc_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1-score for each class\n",
    "y_pred = svc_model.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "f1 = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "classes = unique_labels(svc_model, X_test, y_test)\n",
    "\n",
    "# Print the metrics for each class\n",
    "for i in range(5):\n",
    "    print(f\"{classes[i]}\")\n",
    "    print(f\"  Precision: {precision[i]}\")\n",
    "    print(f\"  Recall: {recall[i]}\")\n",
    "    print(f\"  F1-score: {f1[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = col_transf(X_train)\n",
    "rfc_model = bestRFC(ct, X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "save_model(rfc_model, \"models\", \"best_rfc_model.pkl\")\n",
    "\n",
    "# Load the model\n",
    "loaded_rfc_model = load_model(\"models\", \"best_rfc_model.pkl\")\n",
    "\n",
    "acc_train, acc_test = calculate_accuracy(X_train, y_train, X_test, y_test, loaded_rfc_model)\n",
    "bacc_train, bacc_test = calculate_bal_accuracy(X_train, y_train, X_test, y_test, loaded_rfc_model)\n",
    "acc_train_w, acc_test_w = calculate_accuracy_w(X_train, y_train, X_test, y_test, loaded_rfc_model)\n",
    "bacc_train_w, bacc_test_w = calculate_bal_accuracy_w(X_train, y_train, X_test, y_test, loaded_rfc_model)\n",
    "\n",
    "print(f\"\\nAccuracy on the train set: {acc_train}\")\n",
    "print(f\"Accuracy on the test set: {acc_test}\")\n",
    "\n",
    "print(f\"\\nBalanced Accuracy on the train set best SVC: {bacc_train}\")\n",
    "print(f\"Balanced Accuracy on the test set best SVC: {bacc_test}\")\n",
    "\n",
    "print(f\"\\nAccuracy on the train set (class weights): {acc_train_w}\")\n",
    "print(f\"Accuracy on the test (class weights): {acc_test_w}\")\n",
    "\n",
    "print(f\"\\nBalanced Accuracy on the train set (class weights): {bacc_train_w}\")\n",
    "print(f\"Balanced Accuracy on the test set (class weights): {bacc_test_w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(rfc_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1-score for each class\n",
    "y_pred = rfc_model.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "f1 = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "classes = unique_labels(rfc_model, X_test, y_test)\n",
    "\n",
    "# Print the metrics for each class\n",
    "for i in range(5):\n",
    "    print(f\"{classes[i]}\")\n",
    "    print(f\"  Precision: {precision[i]}\")\n",
    "    print(f\"  Recall: {recall[i]}\")\n",
    "    print(f\"  F1-score: {f1[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = col_transf(X_train)\n",
    "knn_model = bestKNN(ct, X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "save_model(knn_model, \"models\", \"best_knn_model.pkl\")\n",
    "\n",
    "# Load the model\n",
    "loaded_knn_model = load_model(\"models\", \"best_knn_model.pkl\")\n",
    "\n",
    "acc_train, acc_test = calculate_accuracy(X_train, y_train, X_test, y_test, loaded_knn_model)\n",
    "bacc_train, bacc_test = calculate_bal_accuracy(X_train, y_train, X_test, y_test, loaded_knn_model)\n",
    "\n",
    "print(f\"\\nAccuracy on the train set: {acc_train}\")\n",
    "print(f\"Accuracy on the test set: {acc_test}\")\n",
    "\n",
    "print(f\"\\nBalanced Accuracy on the train set best SVC: {bacc_train}\")\n",
    "print(f\"Balanced Accuracy on the test set best SVC: {bacc_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(knn_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1-score for each class\n",
    "y_pred = knn_model.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "f1 = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "classes = unique_labels(knn_model, X_test, y_test)\n",
    "\n",
    "# Print the metrics for each class\n",
    "for i in range(5):\n",
    "    print(f\"{classes[i]}\")\n",
    "    print(f\"  Precision: {precision[i]}\")\n",
    "    print(f\"  Recall: {recall[i]}\")\n",
    "    print(f\"  F1-score: {f1[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = col_transf(X_train)\n",
    "nb_model = bestNaiveBayes(ct, X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "save_model(nb_model, \"models\", \"best_nb_model.pkl\")\n",
    "\n",
    "# Load the model\n",
    "loaded_nb_model = load_model(\"models\", \"best_nb_model.pkl\")\n",
    "\n",
    "acc_train, acc_test = calculate_accuracy(X_train, y_train, X_test, y_test, loaded_nb_model)\n",
    "bacc_train, bacc_test = calculate_bal_accuracy(X_train, y_train, X_test, y_test, loaded_nb_model)\n",
    "\n",
    "print(f\"\\nAccuracy on the train set: {acc_train}\")\n",
    "print(f\"Accuracy on the test set: {acc_test}\")\n",
    "\n",
    "print(f\"\\nBalanced Accuracy on the train set best SVC: {bacc_train}\")\n",
    "print(f\"Balanced Accuracy on the test set best SVC: {bacc_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(nb_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1-score for each class\n",
    "y_pred = nb_model.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "f1 = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "classes = unique_labels(nb_model, X_test, y_test)\n",
    "\n",
    "# Print the metrics for each class\n",
    "for i in range(5):\n",
    "    print(f\"{classes[i]}\")\n",
    "    print(f\"  Precision: {precision[i]}\")\n",
    "    print(f\"  Recall: {recall[i]}\")\n",
    "    print(f\"  F1-score: {f1[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots that compares the features of the labeled and the unlabeled data for the SVC classifier\n",
    "\n",
    "X_labeled = df_train\n",
    "X_unlabeled = pd.read_csv(\"Data/unlabeled_sample01_cellpose.csv\").drop(['Image ID'], axis=1)\n",
    "\n",
    "y_labeled = y_train\n",
    "y_pred_unlabeled = svc_model.predict(X_unlabeled)\n",
    "\n",
    "X_unlabeled['Labels'] = y_pred_unlabeled\n",
    "\n",
    "# Get the unique labels\n",
    "unique_labels = np.unique(y_labeled)\n",
    "\n",
    "# Assign colors to the labels for visualization\n",
    "label_colors = plt.cm.get_cmap('jet', len(unique_labels))\n",
    "for label in range(0,5):\n",
    "    # Plot the unlabeled data with predicted labels\n",
    "    unlabeled_data = X_unlabeled[X_unlabeled['Labels'] == unique_labels[label]]\n",
    "    plt.scatter(unlabeled_data['Volume'], unlabeled_data['Roundness'], color='red', marker='x', label=f'Unlabeled Data (Predicted {unique_labels[label].decode()})', alpha=0.2)\n",
    "    \n",
    "    # Plot the labeled data\n",
    "    labeled_data = X_labeled[X_labeled['Labels'] == unique_labels[label]]\n",
    "    plt.scatter(labeled_data['Volume'], labeled_data['Roundness'], color='blue', label=f'Labeled Data ({unique_labels[label].decode()})')\n",
    "    \n",
    "    \n",
    "    # Set plot labels and legend\n",
    "    plt.xlabel('Volume')\n",
    "    plt.ylabel('Roundness')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots that compares the features of the labeled and the unlabeled data for the RFC classifier\n",
    "\n",
    "X_labeled = df_train\n",
    "X_unlabeled = pd.read_csv(\"Data/unlabeled_sample01_cellpose.csv\").drop(['Image ID'], axis=1)\n",
    "\n",
    "y_labeled = y_train\n",
    "y_pred_unlabeled = rfc_model.predict(X_unlabeled)\n",
    "\n",
    "X_unlabeled['Labels'] = y_pred_unlabeled\n",
    "\n",
    "# Get the unique labels\n",
    "unique_labels = np.unique(y_labeled)\n",
    "\n",
    "# Assign colors to the labels for visualization\n",
    "label_colors = plt.cm.get_cmap('jet', len(unique_labels))\n",
    "for label in range(0,5):\n",
    "    # Plot the unlabeled data with predicted labels\n",
    "    unlabeled_data = X_unlabeled[X_unlabeled['Labels'] == unique_labels[label]]\n",
    "    plt.scatter(unlabeled_data['Volume'], unlabeled_data['Roundness'], color='red', marker='x', label=f'Unlabeled Data (Predicted {unique_labels[label].decode()})', alpha=0.2)\n",
    "    # Plot the labeled data\n",
    "    labeled_data = X_labeled[X_labeled['Labels'] == unique_labels[label]]\n",
    "    plt.scatter(labeled_data['Volume'], labeled_data['Roundness'], color='blue', label=f'Labeled Data ({unique_labels[label].decode()})')\n",
    "    \n",
    "    \n",
    "    # Set plot labels and legend\n",
    "    plt.xlabel('Volume')\n",
    "    plt.ylabel('Roundness')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots that compares the features of the labeled and the unlabeled data for the kNN classifier\n",
    "\n",
    "X_labeled = df_train\n",
    "X_unlabeled = pd.read_csv(\"Data/unlabeled_sample01_cellpose.csv\").drop(['Image ID'], axis=1)\n",
    "\n",
    "y_labeled = y_train\n",
    "y_pred_unlabeled = knn_model.predict(X_unlabeled)\n",
    "\n",
    "X_unlabeled['Labels'] = y_pred_unlabeled\n",
    "\n",
    "# Get the unique labels\n",
    "unique_labels = np.unique(y_labeled)\n",
    "\n",
    "# Assign colors to the labels for visualization\n",
    "label_colors = plt.cm.get_cmap('jet', len(unique_labels))\n",
    "for label in range(0,5):\n",
    "    # Plot the unlabeled data with predicted labels\n",
    "    unlabeled_data = X_unlabeled[X_unlabeled['Labels'] == unique_labels[label]]\n",
    "    plt.scatter(unlabeled_data['Volume'], unlabeled_data['Roundness'], color='red', marker='x', label=f'Unlabeled Data (Predicted {unique_labels[label].decode()})', alpha=0.2)\n",
    "    # Plot the labeled data\n",
    "    labeled_data = X_labeled[X_labeled['Labels'] == unique_labels[label]]\n",
    "    plt.scatter(labeled_data['Volume'], labeled_data['Roundness'], color='blue', label=f'Labeled Data ({unique_labels[label].decode()})')\n",
    "    \n",
    "    \n",
    "    # Set plot labels and legend\n",
    "    plt.xlabel('Volume')\n",
    "    plt.ylabel('Roundness')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
